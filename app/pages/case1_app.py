import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
import io
from datetime import datetime, timedelta

# å¯¼å…¥è·¯å¾„ä¿®å¤
current_dir = os.path.dirname(os.path.abspath(__file__))
app_dir = os.path.dirname(current_dir)
project_dir = os.path.dirname(app_dir)
sys.path.append(project_dir)

# ä½¿ç”¨ç›¸å¯¹å¯¼å…¥ (å°è¯•ç›´æ¥å¯¼å…¥ï¼Œå¦‚æœä¸è¡Œåˆ™ç”¨ä¸‹é¢çš„ sys.path.append)
sys.path.append(os.path.join(project_dir, "app", "utils"))
from data_loader import load_case1_data, validate_case1_data
from case1_predictor import generate_sales_forecast # ä¿®æ”¹æ­¤è¡Œ

# é¡¶çº§æ’åºå‡½æ•°ï¼Œç¡®ä¿æ‰€æœ‰å›¾è¡¨éƒ½èƒ½æ­£ç¡®ä½¿ç”¨
def sort_key_date(date_str):
    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
                 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}
    try:
        parts = str(date_str).split('-') #ç¡®ä¿è¾“å…¥æ˜¯å­—ç¬¦ä¸²
        if len(parts) == 3: # "YYYY-Mon-wkN"
            year_str, month_str, week_str = parts[0], parts[1], parts[2]
            year = int(year_str)
            month_num = month_map.get(month_str, 0)
            week_num = int(week_str.replace('wk',''))
            return (year, month_num, week_num)
        elif len(parts) == 2: # Fallback for "Mon-wkN" (å¦‚æœåŸå§‹æ•°æ®åªæœ‰æœˆå’Œå‘¨)
            month_str, week_str = parts[0], parts[1]
            month_num = month_map.get(month_str, 0)
            week_num = int(week_str.replace('wk',''))
            # å‡è®¾ä¸€ä¸ªé»˜è®¤å¹´ä»½æˆ–åŸºäºå½“å‰ä¸Šä¸‹æ–‡çš„å¹´ä»½ï¼Œè¿™é‡Œç”¨0è¡¨ç¤ºæ— ç‰¹å®šå¹´ä»½æˆ–æœ€æ—©
            # åœ¨load_case1_dataä¸­ï¼Œè¿™äº›æ—¥æœŸä¼šè¢«èµ‹äºˆå¹´ä»½ï¼Œæ‰€ä»¥è¿™é‡Œä¸»è¦æ˜¯ä¸ºäº†ç¨³å¥æ€§
            return (0, month_num, week_num) 
        else: # Malformed
            return (float('inf'), float('inf'), float('inf')) # ä½¿æ ¼å¼é”™è¯¯çš„æ’åœ¨æœ€å
    except ValueError: 
        return (float('inf'), float('inf'), float('inf')) 
    except Exception: 
        return (float('inf'), float('inf'), float('inf'))

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¡ˆä¾‹1: é”€é‡é¢„æµ‹åˆ†æ",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("Case 1: Sales Forecast Analysis")

# åŠ è½½æ•°æ®
@st.cache_data # æ·»åŠ ç¼“å­˜ä»¥æé«˜æ€§èƒ½
def load_data():
    data_dict = load_case1_data()
    if not validate_case1_data(data_dict):
        st.error("æ— æ³•åŠ è½½æœ‰æ•ˆçš„é”€é‡é¢„æµ‹æ•°æ®")
        return None
    return data_dict.get('historical_sales')

with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
    raw_sales_data = load_data()
    if raw_sales_data is None:
        st.stop()

    # é‡å‘½ååˆ—ä»¥åŒ¹é… case1_predictor.py çš„æœŸæœ›
    # case1_app.py ä¸­çš„åˆ—: 'product', 'region', 'date', 'sales', 'price'
    # case1_predictor.py æœŸæœ›: 'Product', 'Region', 'Week', 'Sales' (Price åœ¨ reference_products_info ä¸­)
    sales_data_for_predictor = raw_sales_data.rename(columns={
        'product': 'Product',
        'region': 'Region',
        'date': 'Week', # 'date' åˆ—çš„æ ¼å¼æ˜¯ 'Sep-wk1', 'Sep-wk2' ç­‰ï¼Œä¸ 'Week' è¯­ä¹‰ä¸€è‡´
        'sales': 'Sales'
    })
    # ç¡®ä¿ 'Week' åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå¦‚æœå®ƒæ˜¯ Categoricalï¼Œè½¬æ¢å®ƒ
    if isinstance(sales_data_for_predictor['Week'].dtype, pd.CategoricalDtype): # ä¿®æ­£ DeprecationWarning
        sales_data_for_predictor['Week'] = sales_data_for_predictor['Week'].astype(str)


# æ•°æ®æ¦‚è§ˆ
st.header("1. Data Overview")

st.subheader("1.1 Dataset Information")
st.write(f"Records: {raw_sales_data.shape[0]} rows, {raw_sales_data.shape[1]} columns")
st.write("Columns: ", ", ".join(raw_sales_data.columns.tolist()))

# æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
st.subheader("1.2 Historical Sales Data Preview")
st.dataframe(raw_sales_data.head(10), use_container_width=True)

# åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
st.subheader("1.3 Basic Statistics")
st.dataframe(raw_sales_data.describe(include='all'), use_container_width=True)

# æ•°æ®å¯è§†åŒ–
st.header("2. Data Visualization")

# äº§å“åˆ†å¸ƒ
st.subheader("2.1 Product Sales Distribution")
product_sales = raw_sales_data.groupby('product')['sales'].sum().reset_index()
fig_prod, ax_prod = plt.subplots(figsize=(10, 6))
sns.barplot(data=product_sales, x='product', y='sales', ax=ax_prod)
ax_prod.set_title('Total Sales by Product')
ax_prod.tick_params(axis='x', rotation=45)
st.pyplot(fig_prod)

# åœ°åŒºåˆ†å¸ƒ
st.subheader("2.2 Regional Sales Distribution")
region_sales = raw_sales_data.groupby('region')['sales'].sum().reset_index()
fig_reg, ax_reg = plt.subplots(figsize=(10, 6))
sns.barplot(data=region_sales, x='region', y='sales', ax=ax_reg)
ax_reg.set_title('Total Sales by Region')
st.pyplot(fig_reg)

# æ—¶é—´è¶‹åŠ¿åˆ†æ
st.subheader("2.3 Time Trend Analysis")

# æå–æ—¶é—´ä¿¡æ¯å¹¶æŒ‰å‘¨èšåˆ
# ç¡®ä¿ 'date' åˆ—æ˜¯ Categorical ä»¥ä¾¿æ­£ç¡®æ’åº
if not isinstance(raw_sales_data['date'].dtype, pd.CategoricalDtype):
    unique_sorted_dates = sorted(raw_sales_data['date'].unique(), key=sort_key_date)
    raw_sales_data['date'] = pd.Categorical(raw_sales_data['date'],
                                        categories=unique_sorted_dates,
                                        ordered=True)

time_sales = raw_sales_data.groupby(['date'], observed=True)['sales'].sum().reset_index()

fig_time, ax_time = plt.subplots(figsize=(14, 8))
sns.lineplot(data=time_sales, x='date', y='sales', marker='o', ax=ax_time)
ax_time.set_title('Sales Trend Over Time')
ax_time.tick_params(axis='x', rotation=90)
ax_time.grid(True, linestyle='--', alpha=0.7)
st.pyplot(fig_time)

# äº¤äº’å¼äº§å“å’Œåœ°åŒºé€‰æ‹©çš„æ—¶é—´åºåˆ—
st.subheader("2.4 Interactive Time Series Analysis")

# ä¾§è¾¹æ  - è¿‡æ»¤æ¡ä»¶
st.sidebar.header("Data Filtering for Visualization")
selected_products_viz = st.sidebar.multiselect(
    "Select Products for Visualization",
    options=raw_sales_data['product'].unique(),
    default=raw_sales_data['product'].unique()[0:1] # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª
)

selected_regions_viz = st.sidebar.multiselect(
    "Select Regions for Visualization",
    options=raw_sales_data['region'].unique(),
    default=raw_sales_data['region'].unique()[0:1] # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª
)

# æ ¹æ®ç­›é€‰æ¡ä»¶è¿‡æ»¤æ•°æ®
if selected_products_viz and selected_regions_viz:
    filtered_data_viz = raw_sales_data[
        (raw_sales_data['product'].isin(selected_products_viz)) & 
        (raw_sales_data['region'].isin(selected_regions_viz))
    ]

    # æŒ‰æ—¥æœŸå’Œäº§å“èšåˆ
    if not filtered_data_viz.empty:
        # ç»˜åˆ¶äº¤äº’å¼å›¾è¡¨
        pivot_data_viz = filtered_data_viz.pivot_table(
            index='date', 
            columns=['product', 'region'], 
            values='sales',
            aggfunc='sum'
        ).fillna(0)
        
        fig_interact, ax_interact = plt.subplots(figsize=(14, 8))
        pivot_data_viz.plot(ax=ax_interact, marker='o')
        ax_interact.set_title('Sales Trends by Product and Region')
        ax_interact.tick_params(axis='x', rotation=90)
        ax_interact.grid(True, linestyle='--', alpha=0.7)
        ax_interact.legend(title='Product - Region')
        st.pyplot(fig_interact)
    else:
        st.warning("No data for selected products and regions in visualization.")
else:
    st.info("Please select at least one product and one region for interactive visualization.")

# é”€é‡é¢„æµ‹æ¨¡å‹
st.header("3. Sales Forecasting Model for Superman Plus")

# --- å‚æ•°è¾“å…¥ ---
st.subheader("3.1 Prediction Parameters")
product_to_forecast = "Superman Plus" # å›ºå®šé¢„æµ‹ç›®æ ‡
st.write(f"Forecasting sales for: **{product_to_forecast}**")

with st.expander("Adjust Prediction Parameters", expanded=True):
    ref_cols = st.columns(2)
    with ref_cols[0]:
        st.markdown("##### Target Product: Superman Plus")
        target_price = st.number_input("Superman Plus Price", min_value=0.0, value=205.0, step=5.0)
        battery_impact = st.slider("Battery Upgrade Impact (%)", min_value=-20.0, max_value=50.0, value=5.0, step=1.0) / 100.0
        
    with ref_cols[1]:
        st.markdown("##### Launch Impact")
        weeks_launch_impact = st.number_input("Weeks for Launch Impact", min_value=0, max_value=20, value=4, step=1)

    st.markdown("---")
    st.markdown("##### Reference Product Information")
    
    # Princess Plus
    st.markdown("###### Princess Plus")
    pp_cols = st.columns(2)
    pp_price = pp_cols[0].number_input("Princess Plus Price", min_value=0.0, value=180.0, step=5.0, key="pp_price")
    pp_weight = pp_cols[1].slider("Princess Plus Weight for Reference", min_value=0.0, max_value=1.0, value=0.7, step=0.05, key="pp_weight")

    # Dwarf Plus
    st.markdown("###### Dwarf Plus")
    dp_cols = st.columns(2)
    dp_price = dp_cols[0].number_input("Dwarf Plus Price", min_value=0.0, value=120.0, step=5.0, key="dp_price")
    dp_weight = dp_cols[1].slider("Dwarf Plus Weight for Reference", min_value=0.0, max_value=1.0, value=0.3, step=0.05, key="dp_weight")

    # ç¡®ä¿æƒé‡å’Œä¸º1çš„æç¤ºæˆ–è‡ªåŠ¨è°ƒæ•´ (predictorä¸­å·²åŒ…å«å½’ä¸€åŒ–)
    if not np.isclose(pp_weight + dp_weight, 1.0) and (pp_weight + dp_weight > 0):
        st.warning(f"Sum of weights ({pp_weight + dp_weight:.2f}) is not 1. The predictor will normalize them. For direct control, please adjust to sum to 1.")
    elif (pp_weight + dp_weight == 0):
        st.warning("Both reference product weights are zero. Prediction will be based on other factors or might be zero if no other base.")

    reference_products_info_input = {
        'Princess Plus': {'Price': pp_price, 'Weight': pp_weight},
        'Dwarf Plus': {'Price': dp_price, 'Weight': dp_weight}
    }
    
    st.markdown("---")
    st.markdown("##### Regional Parameters")
    regions = sales_data_for_predictor['Region'].unique()
    
    price_elasticity_params_input = {}
    price_sensitivity_params_input = {}
    launch_time_impact_params_input = {}

    reg_param_cols = st.columns(len(regions))
    default_elasticity = {'AMR': -1.0, 'Europe': -0.5, 'PAC': -1.5}
    default_sensitivity = {'AMR': 1.0, 'Europe': 0.5, 'PAC': 1.5}
    default_launch_impact_region = {'AMR': 0.05, 'Europe': 0.05, 'PAC': 0.05}

    for i, region in enumerate(regions):
        with reg_param_cols[i]:
            st.markdown(f"###### {region}")
            price_elasticity_params_input[region] = st.number_input(
                f"Price Elasticity ({region})", value=default_elasticity.get(region, -0.5), step=0.1, key=f"elast_{region}"
            )
            price_sensitivity_params_input[region] = st.number_input(
                f"Price Sensitivity ({region})", value=default_sensitivity.get(region, 1.0), step=0.1, key=f"sens_{region}"
            )
            launch_time_impact_params_input[region] = st.slider(
                f"Launch Impact ({region}) (%)", min_value=-20.0, max_value=50.0, value=default_launch_impact_region.get(region, 0.05)*100, step=1.0, key=f"launch_reg_{region}"
            ) / 100.0
            
# è°ƒç”¨é¢„æµ‹å‡½æ•°
if st.button("ğŸš€ Generate Forecast"):
    with st.spinner("Generating sales forecast..."):
        predicted_sales_df = generate_sales_forecast(
            historical_sales_data=sales_data_for_predictor, # ä½¿ç”¨é‡å‘½ååçš„æ•°æ®
            product_to_forecast=product_to_forecast,
            target_product_price=target_price,
            reference_products_info=reference_products_info_input,
            price_elasticity_params=price_elasticity_params_input,
            price_sensitivity_params=price_sensitivity_params_input,
            battery_upgrade_impact=battery_impact,
            launch_time_impact_params=launch_time_impact_params_input,
            weeks_for_launch_impact=weeks_launch_impact
        )
    
    st.session_state['predicted_sales_df'] = predicted_sales_df # å­˜å‚¨åˆ° session_state
else:
    # å¦‚æœ session_state ä¸­æœ‰æ—§çš„é¢„æµ‹ç»“æœï¼Œåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™ä¸ºç©º
    if 'predicted_sales_df' not in st.session_state:
        st.session_state['predicted_sales_df'] = pd.DataFrame(columns=['Region', 'Week', 'Predicted_Sales'])


# é¢„æµ‹ç»“æœå±•ç¤º
st.subheader("3.2 Forecast Results")
predicted_sales_df_display = st.session_state.get('predicted_sales_df', pd.DataFrame(columns=['Region', 'Week', 'Predicted_Sales']))

if not predicted_sales_df_display.empty:
    # ç¡®ä¿é¢„æµ‹ç»“æœä¸­çš„ 'Week' åˆ—ä¹ŸæŒ‰ç…§æ­£ç¡®çš„æ—¶åºæ’åˆ—
    if 'Week' in predicted_sales_df_display.columns and not predicted_sales_df_display.empty:
        # ä½¿ç”¨ sort_key_date å¯¹é¢„æµ‹ç»“æœä¸­å®é™…å­˜åœ¨çš„å‘¨è¿›è¡Œæ’åº
        forecast_unique_weeks = predicted_sales_df_display['Week'].unique()
        
        # ç¡®ä¿ forecast_unique_weeks ä¸­çš„å…ƒç´ æ˜¯å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿ sort_key_date æ­£ç¡®å¤„ç†
        # (generate_sales_forecast è¿”å›çš„Weekåˆ—åº”è¯¥æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œè¿™é‡Œæ˜¯åŒé‡ä¿è¯)
        forecast_unique_weeks_str = [str(w) for w in forecast_unique_weeks]
        
        sorted_forecast_weeks = sorted(forecast_unique_weeks_str, key=sort_key_date)
        
        predicted_sales_df_display['Week'] = pd.Categorical(
            predicted_sales_df_display['Week'].astype(str), # ç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†åˆ›å»ºCategorical
            categories=sorted_forecast_weeks,
            ordered=True
        )
        # æŒ‰åŒºåŸŸå’Œå·²æ’åºçš„å‘¨å†æ¬¡æ’åºæ•´ä¸ªDataFrame
        predicted_sales_df_display = predicted_sales_df_display.sort_values(by=['Region', 'Week']).reset_index(drop=True)

    st.dataframe(predicted_sales_df_display, use_container_width=True)

    st.subheader("3.3 Forecast Visualization")
    
    # å…è®¸ç”¨æˆ·é€‰æ‹©åŒºåŸŸæ¥å¯è§†åŒ–é¢„æµ‹
    available_regions_forecast = predicted_sales_df_display['Region'].unique()
    if len(available_regions_forecast) > 0:
        selected_region_forecast_viz = st.selectbox(
            "Select Region to Visualize Forecast",
            options=available_regions_forecast,
            index=0,
            key="forecast_region_select"
        )
        
        forecast_to_plot = predicted_sales_df_display[predicted_sales_df_display['Region'] == selected_region_forecast_viz]

        if not forecast_to_plot.empty:
            fig_forecast, ax_forecast = plt.subplots(figsize=(14, 7))
            sns.lineplot(data=forecast_to_plot, x='Week', y='Predicted_Sales', marker='o', ax=ax_forecast, label=f"{product_to_forecast} Forecast")
            
            # å¯é€‰ï¼šå åŠ ä¸Šå†å²æ•°æ®è¿›è¡Œå¯¹æ¯” (ä»…é™Dwarf Plus å’Œ Princess Plus)
            # è¿™é‡Œæˆ‘ä»¬åªç”»ç›®æ ‡äº§å“çš„é¢„æµ‹
            
            ax_forecast.set_title(f"Sales Forecast for {product_to_forecast} in {selected_region_forecast_viz}")
            ax_forecast.tick_params(axis='x', rotation=90)
            ax_forecast.grid(True, linestyle='--', alpha=0.7)
            ax_forecast.legend()
            st.pyplot(fig_forecast)
        else:
            st.info(f"No forecast data to display for {selected_region_forecast_viz}.")
    else:
        st.info("No regions found in the forecast data to visualize.")
        
else:
    st.info("Click 'Generate Forecast' to see the results.")

# ... (é¡µè„šæˆ–å…¶ä»–å†…å®¹å¯ä»¥ä¿ç•™)

st.markdown("---")
st.caption("Sales Forecasting Model for Superman Plus - End of Page")

# ç»“è®ºä¸ä¸šåŠ¡å»ºè®®
st.header("4. Conclusions and Business Recommendations")

st.markdown("""
Based on our analysis and forecast results, we can make the following business recommendations:

1. **Product Strategy**:
   - **Princess Plus**: Maintain strong sales in the PAC region, while considering promotions in Europe to increase market share
   - **Dwarf Plus**: Performs well in the AMR region, consider expanding the product line or launching limited editions to boost sales

2. **Regional Strategy**:
   - **PAC**: Key market for Princess Plus, should maintain market leadership position
   - **AMR**: Important market for Dwarf Plus, consider bundled sales strategies
   - **Europe**: Requires special attention, consider targeted promotional activities

3. **Timing Strategy**:
   - Increase inventory preparation 1-2 weeks before forecast sales peaks
   - Conduct product promotions during sales troughs to balance sales

4. **Pricing Strategy**:
   - Based on forecast sales fluctuations, adopt different pricing strategies at different times
   - Consider offering small price discounts during periods of intense competition
""")

# åº•éƒ¨ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.info("This application demonstrates the complete process of sales forecast analysis, including data exploration, visualization, and predictive modeling.") 